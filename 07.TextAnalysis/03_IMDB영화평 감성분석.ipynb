{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# IMDB 영화평감성분석"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         id  sentiment                                             review\n",
       "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
       "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
       "3  \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
       "4  \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>sentiment</th>\n      <th>review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>\"5814_8\"</td>\n      <td>1</td>\n      <td>\"With all this stuff going down at the moment ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\"2381_9\"</td>\n      <td>1</td>\n      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>\"7759_3\"</td>\n      <td>0</td>\n      <td>\"The film starts with a manager (Nicholas Bell...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>\"3630_4\"</td>\n      <td>0</td>\n      <td>\"It must be assumed that those who praised thi...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>\"9495_8\"</td>\n      <td>1</td>\n      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "df = pd.read_csv('../00.data/IMDB/labeledTrainData.tsv',sep='\\t',header=0,quoting=3)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 25000 entries, 0 to 24999\nData columns (total 3 columns):\n #   Column     Non-Null Count  Dtype \n---  ------     --------------  ----- \n 0   id         25000 non-null  object\n 1   sentiment  25000 non-null  int64 \n 2   review     25000 non-null  object\ndtypes: int64(1), object(2)\nmemory usage: 586.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\"With all this stuff going down at the moment with MJ i\\'ve started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ\\'s feeling towards the press and also the obvious message of drugs are bad m\\'kay.<br /><br />Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring. Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him.<br /><br />The actual feature film bit when it finally sta'"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df.review[0][:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <br /> 태그는 공백으로 변환\n",
    "df['review'] = df.review.str.replace('<br />', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영어 이외의 문자는 공백으로 변환\n",
    "import re\n",
    "df['review'] = df.review.apply(lambda x:re.sub('[^a-zA-Z]', ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((17500, 1), (7500, 1))"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "feature_df = df.drop(['id', 'sentiment'], axis=1, inplace=False)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    feature_df, df.sentiment, test_size=0.3, random_state=156\n",
    ")\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "source": [
    "- CountVectorizer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(stop_words='english', ngram_range=(1,2))\n",
    "count_vect.fit(X_train.review)\n",
    "X_train_count = count_vect.transform(X_train.review)\n",
    "X_test_count = count_vect.transform(X_test.review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.886"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "lr_clf = LogisticRegression(C=10)\n",
    "lr_clf.fit(X_train_count, y_train)\n",
    "pred = lr_clf.predict(X_test_count)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "source": [
    "- TfidfVectorizer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(stop_words='english',ngram_range=(1,2))\n",
    "tfidf_vect.fit(X_train.review)\n",
    "X_train_tfidf = tfidf_vect.transform(X_train.review)\n",
    "X_test_tfidf = tfidf_vect.transform(X_test.review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8936"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "lr_clf = LogisticRegression(C=10)\n",
    "lr_clf.fit(X_train_tfidf, y_train)\n",
    "pred = lr_clf.predict(X_test_tfidf)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "source": [
    "### 모델 저장하고 불러오기"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['model/imdb_lr.pkl']"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "import joblib\n",
    "# 모델 저장하기\n",
    "joblib.dump(tfidf_vect, 'model/imdb_vect.pkl')\n",
    "joblib.dump(lr_clf, 'model/imdb_lr.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러오기\n",
    "new_vect = joblib.load('model/imdb_vect.pkl')\n",
    "new_lr = joblib.load('model/imdb_lr.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_test = new_vect.transform(X_test.review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8936"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "pred = new_lr.predict(new_X_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "source": [
    "### Pipeline을 써서 학습/예측/평가"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Count Vectorizer + Logisitic Regression 정확도: 0.8860\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('count_vect', CountVectorizer(stop_words='english', ngram_range=(1,2))),\n",
    "    ('lr_clf', LogisticRegression(C=10))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train.review, y_train)\n",
    "pred = pipeline.predict(X_test.review)\n",
    "acc = accuracy_score(y_test, pred)\n",
    "print(f'Count Vectorizer + Logisitic Regression 정확도: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['model/pipeline.pkl']"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "joblib.dump(pipeline, 'model/pipeline.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pipe = joblib.load('model/pipeline.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Count Vectorizer + Logisitic Regression 정확도: 0.8860\n"
     ]
    }
   ],
   "source": [
    "pred = new_pipe.predict(X_test.review)\n",
    "acc = accuracy_score(y_test, pred)\n",
    "print(f'Count Vectorizer + Logisitic Regression 정확도: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'analyzer': 'word',\n",
       " 'binary': False,\n",
       " 'decode_error': 'strict',\n",
       " 'dtype': numpy.int64,\n",
       " 'encoding': 'utf-8',\n",
       " 'input': 'content',\n",
       " 'lowercase': True,\n",
       " 'max_df': 1.0,\n",
       " 'max_features': None,\n",
       " 'min_df': 1,\n",
       " 'ngram_range': (1, 2),\n",
       " 'preprocessor': None,\n",
       " 'stop_words': 'english',\n",
       " 'strip_accents': None,\n",
       " 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'tokenizer': None,\n",
       " 'vocabulary': None}"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "count_vect.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'analyzer': 'word',\n",
       " 'binary': False,\n",
       " 'decode_error': 'strict',\n",
       " 'dtype': numpy.float64,\n",
       " 'encoding': 'utf-8',\n",
       " 'input': 'content',\n",
       " 'lowercase': True,\n",
       " 'max_df': 1.0,\n",
       " 'max_features': None,\n",
       " 'min_df': 1,\n",
       " 'ngram_range': (1, 2),\n",
       " 'norm': 'l2',\n",
       " 'preprocessor': None,\n",
       " 'smooth_idf': True,\n",
       " 'stop_words': 'english',\n",
       " 'strip_accents': None,\n",
       " 'sublinear_tf': False,\n",
       " 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'tokenizer': None,\n",
       " 'use_idf': True,\n",
       " 'vocabulary': None}"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "tfidf_vect.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'count_vect__ngram_range' : [(1,1),(1,2)],\n",
    "    'count_vect__max_df': [100,300, 700],\n",
    "    'lr_clf__C': [1,10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 28.6min\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed: 42.7min finished\n",
      "{'count_vect__max_df': 700, 'count_vect__ngram_range': (1, 2), 'lr_clf__C': 1} 0.8736571714181699\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_pipe = GridSearchCV(new_pipe, param_grid=params, cv=3, scoring='accuracy',verbose=1,n_jobs=-1)\n",
    "grid_pipe.fit(X_train.review, y_train)\n",
    "print(grid_pipe.best_params_,grid_pipe.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8794666666666666"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "best = grid_pipe.best_estimator_\n",
    "pred = best.predict(X_test.review)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed: 33.3min finished\n",
      "{'lr_clf__C': 10, 'tfidf_vect__max_df': 700, 'tfidf_vect__ngram_range': (1, 2)} 0.8822287469759523\n",
      "0.8872\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf_vect', TfidfVectorizer(stop_words='english')),\n",
    "    ('lr_clf',LogisticRegression())\n",
    "])\n",
    "params = {\n",
    "    'tfidf_vect__ngram_range' : [(1,1),(1,2)],\n",
    "    'tfidf_vect__max_df': [100,300, 700],\n",
    "    'lr_clf__C': [1,10]\n",
    "}\n",
    "grid_pipe = GridSearchCV(pipeline, param_grid=params, cv=3, scoring='accuracy',verbose=1,n_jobs=-1)\n",
    "grid_pipe.fit(X_train.review, y_train)\n",
    "print(grid_pipe.best_params_,grid_pipe.best_score_)\n",
    "best = grid_pipe.best_estimator_\n",
    "pred = best.predict(X_test.review)\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}